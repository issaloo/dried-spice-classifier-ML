{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialize functions and generator for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(gen1, gen2):\n",
    "    \"\"\"Combine generators of imbalanced datasets into one.\n",
    "    \n",
    "    Args:\n",
    "        gen1 (generator): First generator of image data split\n",
    "            by classes\n",
    "        gen2 (generator): Second generator of image data split\n",
    "            by classes\n",
    "        \n",
    "    Returns:\n",
    "        gen3 (generator): Generator that combines 2 generators\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        img_data1,label1 = next(gen1)\n",
    "        img_data2,label2 = next(gen2)\n",
    "        if ((label1.shape[0] + label2.shape[0]) % 32) != 0:\n",
    "            img_data1, label1 = next(gen1)\n",
    "            img_data2, label2 = next(gen2)\n",
    "        img_data_c = np.concatenate((img_data1, img_data2))\n",
    "\n",
    "        label_size = label1.shape[1] + label2.shape[1]\n",
    "        new_labels1 = np.zeros((label1.shape[0], label_size))\n",
    "        new_labels1[:, :-label2.shape[1]] = label1\n",
    "        new_labels2 = np.zeros((label2.shape[0], label_size))\n",
    "        new_labels2[:, label1.shape[1]:] = label2\n",
    "\n",
    "        labels_c = np.concatenate((new_labels1, new_labels2), axis=0)\n",
    "\n",
    "        shuffler = np.random.permutation(labels_c.shape[0])\n",
    "        labels_c_shuffled = labels_c[shuffler]\n",
    "        img_data_c_shuffled = img_data_c[shuffler]\n",
    "\n",
    "        yield img_data_c_shuffled, labels_c_shuffled\n",
    "\n",
    "def plot_accuracy(history_obj, title):\n",
    "    \"\"\"Plots trained ML model accuracy scores.\n",
    "    \n",
    "    Args:\n",
    "        history_df (obj): Output object from trained ML model \n",
    "        title (str): The desired title of the plot\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    data_acc_df = pd.DataFrame({\n",
    "        'epoch':[*range(1, len(\n",
    "            history_obj.history['categorical_accuracy']) + 1)],\n",
    "        'accuracy':history_obj.history['categorical_accuracy']}) \n",
    "    data_acc_df['Data'] = 'training'\n",
    "    data_vacc_df = pd.DataFrame({\n",
    "        'epoch':[*range(1, len(\n",
    "            history_obj.history['val_categorical_accuracy']) + 1)],\n",
    "        'accuracy':history_obj.history['val_categorical_accuracy']})\n",
    "    data_vacc_df['Data'] = 'validation'\n",
    "    data_m_df = pd.concat((data_acc_df, data_vacc_df), axis=0)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    sns.lineplot(data=data_m_df, x='epoch', y='accuracy', hue='Data')\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.ylim((0.1, 0.9))\n",
    "    plt.show()\n",
    "    \n",
    "# Set up plot styling\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 4 classes.\n",
      "Found 440 images belonging to 1 classes.\n",
      "Found 75 images belonging to 5 classes.\n",
      "Found 75 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize training generator\n",
    "train_datagen= ImageDataGenerator(\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=30,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range=[0.7, 1.0])\n",
    "train_generator_1 = train_datagen.flow_from_directory(\n",
    "        'model_dataset/train/augment',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=26,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=15)\n",
    "train_generator_2 = train_datagen.flow_from_directory(\n",
    "        'model_dataset/train/no_augment',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=6,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=15)\n",
    "train_generator = myGenerator(train_generator_1, train_generator_2)\n",
    "\n",
    "# Initialize validation generator\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        'model_dataset/validation',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=32,\n",
    "        shuffle = True,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Initialize test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory='model_dataset/test',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train CNN model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Layers: 7 | Activation: Relu | Max Filter: 256 | Max FCN: 128\n",
    "feat_extract = models.Sequential()\n",
    "feat_extract.add(layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                        input_shape=(200, 200, 3)))\n",
    "feat_extract.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "feat_extract.add(layers.MaxPooling2D((2, 2)))\n",
    "feat_extract.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "feat_extract.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "feat_extract.add(layers.MaxPooling2D((2, 2)))\n",
    "feat_extract.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "feat_extract.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "feat_extract.add(layers.MaxPooling2D((2, 2)))\n",
    "feat_extract.add(layers.Flatten())\n",
    "\n",
    "x = feat_extract.output\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x =layers.Dropout(0.2)(x)\n",
    "prediction_layer = layers.Dense(5, activation = 'softmax')(x)\n",
    "\n",
    "# Train CNN model\n",
    "vgg16 = Model(inputs=feat_extract.input, outputs=prediction_layer)\n",
    "vgg16.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['CategoricalAccuracy'])\n",
    "\n",
    "history_vgg16 = vgg16.fit(train_generator, steps_per_epoch=steps_per_epoch,\n",
    "                          epochs=75, validation_data=valid_generator,\n",
    "                          validation_steps=2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train features for SVM model\n",
    "for i in range(steps_per_epoch):\n",
    "    (X_sub, y_sub) = next(train_generator)\n",
    "    y_sub = np.argmax(y_sub, axis=1)\n",
    "    if i == 0:\n",
    "        X_train = X_sub.copy()\n",
    "        y_train = y_sub.copy()\n",
    "    else:\n",
    "        X_train = np.append(X_train, X_sub, axis=0)\n",
    "        y_train = np.append(y_train, y_sub, axis=0)\n",
    "X_ext_train = feat_extract.predict(X_train)\n",
    "\n",
    "# Extract validation features for SVM model\n",
    "for i in range(3):\n",
    "    (X_sub, y_sub) = next(valid_generator)\n",
    "    y_sub = np.argmax(y_sub, axis=1)\n",
    "    if i == 0:\n",
    "        X_val = X_sub.copy()\n",
    "        y_val = y_sub.copy()\n",
    "    else:\n",
    "        X_val = np.append(X_val, X_sub, axis=0)\n",
    "        y_val = np.append(y_val, y_sub, axis=0)\n",
    "X_ext_val = feat_extract.predict(X_val)\n",
    "\n",
    "# Extract test features for SVM model\n",
    "y_test = test_generator.classes\n",
    "for i in range(test_generator.samples):\n",
    "    (X_sub, _) = next(test_generator)\n",
    "    if i == 0:\n",
    "        X_test = X_sub.copy()\n",
    "    else:\n",
    "        X_test = np.append(X_test, X_sub, axis=0)\n",
    "X_ext_test = feat_extract.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  dried_basil       0.48      0.47      0.48        64\n",
      "dried_oregano       0.39      0.58      0.47        69\n",
      "dried_parsley       0.84      0.52      0.64        62\n",
      "  dried_thyme       0.39      0.34      0.36        65\n",
      "       random       0.89      0.90      0.89        60\n",
      "\n",
      "     accuracy                           0.56       320\n",
      "    macro avg       0.60      0.56      0.57       320\n",
      " weighted avg       0.59      0.56      0.56       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM classifier\n",
    "svm = SVC(class_weight='balanced')\n",
    "svm.fit(X_ext_train, y_train)\n",
    "\n",
    "# Check for overfitting\n",
    "y_train_pred = svm.predict(X_ext_train)\n",
    "print(classification_report(y_train, y_train_pred,\n",
    "                               target_names=c_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  dried_basil       0.00      0.00      0.00        15\n",
      "dried_oregano       0.28      0.73      0.41        15\n",
      "dried_parsley       0.83      0.33      0.48        15\n",
      "  dried_thyme       0.38      0.20      0.26        15\n",
      "       random       0.80      0.80      0.80        15\n",
      "\n",
      "     accuracy                           0.41        75\n",
      "    macro avg       0.46      0.41      0.39        75\n",
      " weighted avg       0.46      0.41      0.39        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_val_pred = svm.predict(X_ext_val)\n",
    "print(classification_report(y_val, y_val_pred,\n",
    "                               target_names=c_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 105 candidates, totalling 525 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fed915cad532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fit grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ext_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Parameters:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize SVM classifier\n",
    "svm = SVC(class_weight='balanced')\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 'scale', 'auto'],\n",
    "              'kernel': ['linear', 'poly', 'rbf']}\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=grid,\n",
    "                         cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_ext_train, y_train)\n",
    "print('Best Parameters:')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Check for overfitting\n",
    "y_train_pred = svm.predict(X_ext_train)\n",
    "print(classification_report(y_train, y_train_pred,\n",
    "                               target_names=c_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_val_pred = svm.predict(X_ext_val)\n",
    "print(classification_report(y_val, y_val_pred,\n",
    "                               target_names=c_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVM classifier\n",
    "svm = SVC(class_weight='balanced', C=1, gamma=0.1, kernel='rbf')\n",
    "svm.fit(X_ext_train, y_train)\n",
    "\n",
    "# Check for overfitting\n",
    "y_train_pred = svm.predict(X_ext_train)\n",
    "print(classification_report(y_train, y_train_pred,\n",
    "                               target_names=c_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_test_pred = svm.predict(X_ext_test)\n",
    "print(classification_report(y_test, y_test_pred,\n",
    "                               target_names=c_labels))\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "df_cm = pd.DataFrame(cm, index=c_labels, columns=c_labels)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues)\n",
    "plt.ylabel('True', fontsize=14)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
